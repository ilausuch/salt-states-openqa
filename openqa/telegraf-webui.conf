[global_tags]
[agent]
  interval = "10s"
  round_interval = true
  metric_batch_size = 1000
  metric_buffer_limit = 10000
  collection_jitter = "0s"
  flush_interval = "10s"
  flush_jitter = "0s"
  precision = ""
  debug = false
  quiet = false
  logfile = ""
  hostname = ""
  omit_hostname = false

[[outputs.influxdb]]
  urls = ["http://openqa-monitor.qa.suse.de:8086"]
  database = "telegraf"
  username = "admin"
  password = "admin"

[[inputs.cpu]]
  percpu = true
  totalcpu = true
  collect_cpu_time = false
  report_active = false

[[inputs.disk]]
  ignore_fs = ["tmpfs", "devtmpfs", "devfs"]

[[inputs.diskio]]

[[inputs.kernel]]

[[inputs.mem]]

[[inputs.processes]]

[[inputs.swap]]

[[inputs.system]]

[[inputs.net]]

[[inputs.ping]]
  urls = {{ salt['mine.get']('*', 'network.interfaces').keys()|list }}
  count = 1
  ping_interval = 1.0
  timeout = 1.0
  deadline = 10

[[inputs.http]]
  urls = [ "https://openqa.suse.de/admin/influxdb/jobs" ]
  data_format = "influx"
  timeout = "20s"
  interval = "30s"

[[inputs.http]]
  urls = [ "https://openqa.suse.de/admin/influxdb/minion" ]
  data_format = "influx"
  timeout = "20s"
  interval = "1m"

[[inputs.http_response]]
  address = "https://openqa.suse.de/tests"
  interval = "1m"

[[inputs.apache]]
  urls = ["http://localhost/server-status?auto"]

[[inputs.postgresql]]
  address = "postgres://telegraf:telegraf@localhost"
  databases = ["openqa"]

[[inputs.postgresql_extensible]]
  address = "postgres://telegraf:telegraf@localhost/openqa"
  databases = ["openqa"]

  [[inputs.postgresql_extensible.query]]
    sqlquery="select count(id) as \"incompletes_last_24h\" from jobs where result='incomplete' and (reason is null or reason not like 'quit%') and t_finished >= NOW() - interval '24 hour'"

  [[inputs.postgresql_extensible.query]]
    sqlquery="select count(id) as \"incompletes_not_restarted_last_24h\" from jobs where result='incomplete' and (reason is null or reason not like 'quit%') and clone_id is null and t_finished >= NOW() - interval '24 hour'"

[[inputs.logparser]]
  files = ["/var/log/apache2/openqa.access_log"]
  from_beginning = false
  name_override = "apache_log"
  ## For parsing logstash-style "grok" patterns:
  [inputs.logparser.grok]
    patterns = ["%{CUSTOM_LOG}"]
    custom_patterns = '''
      CUSTOM_LOG %{COMBINED_LOG_FORMAT} %{NUMBER:response_time_us:int}
    '''

[[inputs.ntpq]]

{# sync with openqa/monitoring/grafana/webui.services.json - and do not reorder, grafana uses the loop index as id #}
{% for service in ['sshd','openqa-gru','openqa-webui','openqa-livehandler','openqa-scheduler','openqa-websockets','smb','vsftpd','telegraf','salt-master','salt-minion','rsyncd','postgresql','postfix','cron','apache2'] %}
[[inputs.procstat]]
  cgroup = "systemd/system.slice/{{ service }}.service"
{% endfor %}

[[inputs.exec]]
  commands = [
    'bash -c "echo systemd_failed failed=$(systemctl --no-legend --failed | wc -l)i"',
  ]
  data_format = "influx"
